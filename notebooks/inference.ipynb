{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from model import GOPT\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "gopt = GOPT(embed_dim=24, num_heads=1, depth=3, input_dim=84)\n",
    "\n",
    "state_dict = torch.load('exp/models/best_audio_model.pth', map_location='cpu')\n",
    "gopt.load_state_dict(state_dict)\n",
    "gopt.eval()\n",
    "gopt = gopt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scaler(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    return scaler\n",
    "\n",
    "scaler = load_scaler(path=\"resources/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feat = np.load(\"data/seq_data_librispeech/if_feat.npy\")\n",
    "input_phn = np.load(\"data/seq_data_librispeech/if_label.npy\")\n",
    "\n",
    "normed_feat = scaler.transform(input_feat[0])\n",
    "input_feat = torch.from_numpy(normed_feat).unsqueeze(0)\n",
    "phoneme_length = np.sum(input_phn!=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input_feats = input_feat.to(device)\n",
    "    input_phone_ids = torch.from_numpy(input_phn[:,:,0]).to(device)\n",
    "\n",
    "    utt_score, phn_scores, wrd_scores = gopt(input_feats.float(),input_phone_ids.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47]) torch.Size([1]) torch.Size([47])\n"
     ]
    }
   ],
   "source": [
    "phn_scores = phn_scores.view(-1)[0: phoneme_length] * 50\n",
    "utt_score = utt_score.view(-1) * 50\n",
    "wrd_scores = wrd_scores.view(-1)[0:phoneme_length] * 50\n",
    "print(wrd_scores.shape, utt_score.shape, wrd_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(path=\"librispeech-lexicon.txt\"):\n",
    "    with open(path, 'r') as f:\n",
    "        lexicon_raw = f.read()\n",
    "        rows = lexicon_raw.splitlines()\n",
    "    clean_rows = [row.split() for row in rows]\n",
    "    lexicon_dict_l = dict()\n",
    "    for row in clean_rows:\n",
    "        c_row = row.copy()\n",
    "        key = c_row.pop(0)\n",
    "        if len(c_row) == 1:\n",
    "            c_row[0] = c_row[0] + '_S'\n",
    "        if len(c_row) >= 2:\n",
    "            c_row[0] = c_row[0] + '_B'\n",
    "            c_row[-1] = c_row[-1] + '_E'\n",
    "        if len(c_row) > 2:\n",
    "            for i in range(1,len(c_row)-1):\n",
    "                c_row[i] = c_row[i] + '_I'\n",
    "        val = \" \".join(c_row)\n",
    "        lexicon_dict_l[key] = val\n",
    "    return lexicon_dict_l\n",
    "\n",
    "lexicon_path = \"resources/lexicon.txt\"\n",
    "lexicon_dict_l = load_lexicon(lexicon_path)\n",
    "\n",
    "with open(\"resources/phoneme_dict.json\", \"r\") as f:\n",
    "    phone2id = json.load(f)\n",
    "id2phone = {value:key for key, value in phone2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>file_utt</th>\n",
       "      <th>utt</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>id</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>pure_phonemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>237-126133-0013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>102</td>\n",
       "      <td>AY1_S</td>\n",
       "      <td>AY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>237-126133-0013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.10</td>\n",
       "      <td>231</td>\n",
       "      <td>N_B</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>237-126133-0013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.31</td>\n",
       "      <td>248</td>\n",
       "      <td>OW1_E</td>\n",
       "      <td>OW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>237-126133-0013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>175</td>\n",
       "      <td>G_B</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>237-126133-0013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>37</td>\n",
       "      <td>AE1_I</td>\n",
       "      <td>AE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index         file_utt  utt  start  duration   id phonemes  \\\n",
       "0        1      1  237-126133-0013    1   0.42      0.14  102    AY1_S   \n",
       "1        2      2  237-126133-0013    1   0.56      0.10  231      N_B   \n",
       "2        3      3  237-126133-0013    1   0.66      0.31  248    OW1_E   \n",
       "3        5      5  237-126133-0013    1   1.21      0.11  175      G_B   \n",
       "4        6      6  237-126133-0013    1   1.32      0.16   37    AE1_I   \n",
       "\n",
       "  pure_phonemes  \n",
       "0           AY1  \n",
       "1             N  \n",
       "2           OW1  \n",
       "3             G  \n",
       "4           AE1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_force_alignment_result(alignment_path, phones_path):\n",
    "    alignment = pd.read_csv(alignment_path, sep=\"\\s\", names=[\"file_utt\",\"utt\",\"start\",\"duration\",\"id\"], engine='python')\n",
    "    \n",
    "    id2phoneme = pd.read_csv(phones_path, sep=\"\\s\", names=[\"phonemes\", \"id\"], engine='python')\n",
    "    id2phoneme = id2phoneme.set_index(keys=\"id\").to_dict()[\"phonemes\"]\n",
    "    alignment[\"phonemes\"] = alignment.id.apply(lambda x: id2phoneme[int(x)])\n",
    "    \n",
    "    return alignment\n",
    "\n",
    "alignment_path = \"/data/codes/prep_gopt/egs/gop_speechocean762/s5/exp/ali_infer/merged_alignment.txt\"\n",
    "phones_path = \"/data/codes/prep_gopt/egs/gop_speechocean762/s5/data/lang_nosp/phones.txt\"\n",
    "\n",
    "alignment = load_force_alignment_result(alignment_path=alignment_path, phones_path=phones_path)\n",
    "alignment.phonemes = alignment.phonemes.apply(lambda x: x.split(\" \"))\n",
    "alignment = alignment.explode(column=\"phonemes\").reset_index()\n",
    "alignment[\"pure_phonemes\"] = alignment.phonemes.apply(lambda x: x.split(\"_\")[0])\n",
    "alignment = alignment[alignment.phonemes != \"SIL\"].reset_index()\n",
    "alignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word_id</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>pure_phonemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AY1_S</td>\n",
       "      <td>AY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N_B</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OW1_E</td>\n",
       "      <td>OW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>G_B</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AE1_I</td>\n",
       "      <td>AE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index word_id phonemes pure_phonemes\n",
       "0      0       0    AY1_S           AY1\n",
       "1      1       1      N_B             N\n",
       "2      1       1    OW1_E           OW1\n",
       "3      2       2      G_B             G\n",
       "4      2       2    AE1_I           AE1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"JUMPER\"\n",
    "words = text.split(' ')\n",
    "path = \"egs/gop_speechocean762/s5/data/local/text-phone\"\n",
    "\n",
    "text_phone_df = pd.read_csv(path, sep=\"\\t\", names=[\"word_id\", \"phonemes\"], dtype={\"word_id\":str})\n",
    "\n",
    "text_phone_df.word_id = text_phone_df.word_id.apply(lambda x: x.split(\".\")[-1])\n",
    "text_phone_df.phonemes = text_phone_df.phonemes.apply(lambda x: x.split(\" \"))\n",
    "text_phone_df = text_phone_df.explode(column=\"phonemes\").reset_index()\n",
    "text_phone_df[\"pure_phonemes\"] = text_phone_df.phonemes.apply(lambda x: x.split(\"_\")[0])\n",
    "text_phone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word_id</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>pure_phonemes</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>pure_phonemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AY1_S</td>\n",
       "      <td>AY1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.14</td>\n",
       "      <td>AY1_S</td>\n",
       "      <td>AY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N_B</td>\n",
       "      <td>N</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N_B</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OW1_E</td>\n",
       "      <td>OW1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.31</td>\n",
       "      <td>OW1_E</td>\n",
       "      <td>OW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>G_B</td>\n",
       "      <td>G</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>G_B</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AE1_I</td>\n",
       "      <td>AE1</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>AE1_I</td>\n",
       "      <td>AE1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index word_id phonemes pure_phonemes  start  duration phonemes  \\\n",
       "0      0       0    AY1_S           AY1   0.42      0.14    AY1_S   \n",
       "1      1       1      N_B             N   0.56      0.10      N_B   \n",
       "2      1       1    OW1_E           OW1   0.66      0.31    OW1_E   \n",
       "3      2       2      G_B             G   1.21      0.11      G_B   \n",
       "4      2       2    AE1_I           AE1   1.32      0.16    AE1_I   \n",
       "\n",
       "  pure_phonemes  \n",
       "0           AY1  \n",
       "1             N  \n",
       "2           OW1  \n",
       "3             G  \n",
       "4           AE1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_metadata = pd.concat([text_phone_df, alignment[[\"start\", \"duration\", \"phonemes\", \"pure_phonemes\"]]], axis=1)\n",
    "joined_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "20    None\n",
       "21    None\n",
       "22    None\n",
       "23    None\n",
       "24    None\n",
       "25    None\n",
       "26    None\n",
       "27    None\n",
       "28    None\n",
       "29    None\n",
       "30    None\n",
       "31    None\n",
       "32    None\n",
       "33    None\n",
       "34    None\n",
       "35    None\n",
       "36    None\n",
       "37    None\n",
       "38    None\n",
       "39    None\n",
       "40    None\n",
       "41    None\n",
       "42    None\n",
       "43    None\n",
       "44    None\n",
       "45    None\n",
       "46    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_phoneme(phoneme_1, phoneme_2):\n",
    "    assert phoneme_1 == phoneme_2\n",
    "\n",
    "def validate_pure_phoneme(pure_phoneme_1, pure_phoneme_2):\n",
    "    assert pure_phoneme_1 == pure_phoneme_2\n",
    "\n",
    "columns = joined_metadata.columns\n",
    "assert columns[2] == columns[6]\n",
    "assert columns[3] == columns[7]\n",
    "\n",
    "joined_metadata.apply(lambda x: validate_phoneme(x[2], x[6]), axis=1)\n",
    "joined_metadata.apply(lambda x: validate_pure_phoneme(x[3], x[7]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids = torch.tensor([int(i) for i in text_phone_df[\"word_id\"].to_list()])\n",
    "assert input_phone_ids.shape[0] == 1\n",
    "input_phone_ids = input_phone_ids.view(-1)\n",
    "phone_ids = input_phone_ids[input_phone_ids != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "one_hot = F.one_hot(word_ids, num_classes=word_ids.max().item()+1).float()\n",
    "one_hot = one_hot / one_hot.sum(0, keepdim=True)\n",
    "word_scores = torch.matmul(one_hot.transpose(0, 1), phn_scores.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Phoneme:\n",
    "    arpabet: str\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    score: float\n",
    "    \n",
    "    def __init__(self, arpabet, start_time, end_time, score):\n",
    "        self.arpabet = arpabet\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.score = score\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"arpabet\": self.arpabet,\n",
    "            \"start_time\": self.start_time,\n",
    "            \"end_time\": self.end_time,\n",
    "            \"score\": self.score\n",
    "        }\n",
    "        \n",
    "@dataclass\n",
    "class Word:\n",
    "    text: str\n",
    "    arpabet: str\n",
    "    start_time: float\n",
    "    phonemes: List[Phoneme]\n",
    "    end_time: float\n",
    "    score: float\n",
    "    \n",
    "    def __init__(self, text, arpabet, start_time, end_time, score, phonemes):\n",
    "        self.arpabet = arpabet\n",
    "        self.text = text\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.score = score\n",
    "        self.phonemes = phonemes\n",
    "    \n",
    "    def append_phone(self, phone):\n",
    "        self.phonemes.append(phone)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"text\": self.text,\n",
    "            \"arpabet\": self.arpabet,\n",
    "            \"start_time\": self.start_time,\n",
    "            \"end_time\": self.end_time,\n",
    "            \"score\": self.score,\n",
    "            \"phonemes\": [phoneme.to_dict() for phoneme in self.phonemes]\n",
    "\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class Sentence:\n",
    "    arpabet: str\n",
    "    duration: float\n",
    "    score: float\n",
    "    words: List[Word]\n",
    "    \n",
    "    def __init__(self, text, arpabet, duration, score, words):\n",
    "        self.arpabet = arpabet\n",
    "        self.duration = duration\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.words = words\n",
    "        \n",
    "    def append_word(self, word):\n",
    "        self.words.append(word)\n",
    "    \n",
    "    def append_phoneme(self, word_index, phoneme):\n",
    "        self.words[word_index].append_phone(phoneme)\n",
    "        self.words[word_index].end_time = phoneme.end_time \n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"text\": self.text,\n",
    "            \"arpabet\": self.arpabet,\n",
    "            \"duration\": self.duration,\n",
    "            \"phonemes\": [word.to_dict() for word in self.words],\n",
    "            \"score\": self.score\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data/codes/prep_gopt/inference.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     scores \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mutterance\u001b[39m\u001b[39m\"\u001b[39m: utterance\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m scores \u001b[39m=\u001b[39m parse_score(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     transcript\u001b[39m=\u001b[39;49mtext, utt_score\u001b[39m=\u001b[39;49mutt_score, word_scores\u001b[39m=\u001b[39;49mword_scores, phn_scores\u001b[39m=\u001b[39;49mphn_scores)\n",
      "\u001b[1;32m/data/codes/prep_gopt/inference.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     utterance\u001b[39m.\u001b[39mappend_phoneme(word_index\u001b[39m=\u001b[39mword_id, phoneme\u001b[39m=\u001b[39m_tmp_phone)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     _tmp_word \u001b[39m=\u001b[39m Word(\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m         arpabet\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, start_time\u001b[39m=\u001b[39m_tmp_phone\u001b[39m.\u001b[39mstart_time, end_time\u001b[39m=\u001b[39m_tmp_phone\u001b[39m.\u001b[39mend_time, text\u001b[39m=\u001b[39mwords[word_id],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         score\u001b[39m=\u001b[39mword_scores[word_id]\u001b[39m.\u001b[39mitem(), phonemes\u001b[39m=\u001b[39m[_tmp_phone, ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(utterance\u001b[39m.\u001b[39mwords) \u001b[39m==\u001b[39m word_id:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B14.162.145.55/data/codes/prep_gopt/inference.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m         utterance\u001b[39m.\u001b[39mappend_word(_tmp_word)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def parse_score(transcript, utt_score, word_scores, phn_scores):\n",
    "    words = transcript.split(\" \")\n",
    "    _tmp_word = Word(\n",
    "        text=words[0], \n",
    "        arpabet=None,\n",
    "        score=word_scores[0].item(), \n",
    "        end_time=0, \n",
    "        start_time=0, \n",
    "        phonemes=[]\n",
    "    )\n",
    "    \n",
    "    utterance = Sentence(\n",
    "        text=transcript,\n",
    "        arpabet=None, \n",
    "        score=utt_score.item(), \n",
    "        duration=0.0, \n",
    "        words=[],\n",
    "    )\n",
    "    curr_word_id = -1\n",
    "    for index in range(len(phone_ids)):\n",
    "        word_id = int(joined_metadata[\"word_id\"][index])\n",
    "        start_time = joined_metadata[\"start\"][index]\n",
    "        end_time = start_time + joined_metadata[\"duration\"][index]\n",
    "        \n",
    "        _tmp_phone = Phoneme(\n",
    "            arpabet=id2phone[int(phone_ids[index])],\n",
    "            end_time=end_time, start_time=start_time,\n",
    "            score=phn_scores[index].item()\n",
    "        )\n",
    "\n",
    "        if word_id == curr_word_id:\n",
    "            utterance.append_phoneme(word_index=word_id, phoneme=_tmp_phone)\n",
    "        else:\n",
    "            _tmp_word = Word(\n",
    "                arpabet=None, start_time=_tmp_phone.start_time, end_time=_tmp_phone.end_time, text=words[word_id],\n",
    "                score=word_scores[word_id].item(), phonemes=[_tmp_phone, ]\n",
    "            )\n",
    "            if len(utterance.words) == word_id:\n",
    "                utterance.append_word(_tmp_word)\n",
    "            else:\n",
    "                utterance.append_phoneme(word_index=word_id, phoneme=_tmp_phone)\n",
    "    scores = {\n",
    "        \"version\": \"None\",\n",
    "        \"utterance\": utterance.to_dict()\n",
    "        }\n",
    "    return scores\n",
    "\n",
    "scores = parse_score(\n",
    "    transcript=text, utt_score=utt_score, word_scores=word_scores, phn_scores=phn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_score(transcript, utt_score, word_scores, phn_scores):\n",
    "#     curr_word_id = -1\n",
    "    \n",
    "#     _tmp_word = {\n",
    "#             \"text\": words[0],\n",
    "#             \"score\": word_scores[0].item(),\n",
    "#             \"phonemes\": []\n",
    "#         }\n",
    "\n",
    "#     scores = {\n",
    "#         \"version\": \"None\",\n",
    "#         \"utterance\": {\n",
    "#             \"text\": text,\n",
    "#             \"score\": utt_score.item(),\n",
    "#             \"words\": []\n",
    "#         }\n",
    "#     }\n",
    "#     for index in range(len(phone_ids)):\n",
    "#         word_id = int(phone_df[\"word_id\"][index])\n",
    "\n",
    "#         _tmp_phone = {\n",
    "#             \"text\": id2phone[int(phone_ids[index])],\n",
    "#             \"score\": phn_scores[index].item(),\n",
    "#         }\n",
    "\n",
    "#         if word_id == curr_word_id:\n",
    "#             scores[\"utterance\"][\"words\"][word_id][\"phonemes\"].append(\n",
    "#                 _tmp_phone\n",
    "#             )\n",
    "#         else:\n",
    "#             _tmp_word = {\n",
    "#                 \"text\": words[word_id],\n",
    "#                 \"score\": word_scores[word_id].item(),\n",
    "#                 \"phonemes\": []\n",
    "#             }\n",
    "\n",
    "#             _tmp_word[\"phonemes\"].append(_tmp_phone)\n",
    "#             if len(scores[\"utterance\"][\"words\"]) == word_id:\n",
    "#                 scores[\"utterance\"][\"words\"].append(_tmp_word)\n",
    "#             else:\n",
    "#                 scores[\"utterance\"][\"words\"][word_id][\"phonemes\"].append(\n",
    "#                     _tmp_phone\n",
    "#                 )\n",
    "    \n",
    "#     return scores\n",
    "\n",
    "# scores = parse_score(\n",
    "#     transcript=text, utt_score=utt_score, word_scores=word_scores, phn_scores=phn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json_obj = json.dumps(scores, indent=4, ensure_ascii=False)\n",
    "    f.write(json_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
